# A 股中低频 + 日内 T+0 量化模型评估报告（含数据源与算力分析）

## 1. 背景与目标

- **交易频率**：中低频  
  - 日级调仓 + 日内有限次数的 T+0（5–30 分钟级别），不做毫秒级高频。
- **标的范围**：A 股已持仓股票为主，目标是：
  - 通过趋势 & 短期波动预测，**降低持仓成本、提升收益**（做 T）。
- **现有系统能力**：
  - 已有统一数据接入（行情、技术指标、资金、筹码、情绪、公告新闻、研报、财务、风险等），用于趋势 & 多维分析师。
- **新需求**：
  - 将 **ARIMA / HMM / LSTM / Transformer / DeepAR / FinMamba** 等模型  
    作为趋势/短期预测引擎，输出结果用于量化策略的实时或准实时调整。
  - 只考虑中低频和日内 T+0，对算力与数据源做现实可行的选择。

---

## 2. 已具备与可补充的数据源能力

### 2.1 现有内生数据（来自现有系统）

- **日级行情 & 技术指标**
  - 日 K：OHLCV、金额、复权价。
  - 技术指标：MA、RSI、MACD、BOLL、KDJ、量比等。

- **资金 & 筹码**
  - 主力资金净流入、资金流分布。
  - 筹码分布：成本区间、集中度、大股东持股等。

- **基本面 & 事件**
  - 年报/季报及财务比率（估值、成长性、盈利能力）。
  - 公告（结构化摘要 + PDF 抽取）、新闻与研报（文本 & 情绪分析）。

- **情绪 & 风险**
  - 市场情绪评分。
  - 风险事件：限售解禁、减持、质押等结构化时间表。

> 这些数据已可用于 **日级趋势 + 多周期预期** 的建模和解释。

---

### 2.2 TDX 数据源能力（`tdx_doc`）

从 `README.md` / `API_接口文档.md` / `API_集成指南.md` / `API_完成总结.md` / `API_使用示例.py` 可见：

#### 2.2.1 行情 & K 线

- **实时五档盘口**：`GET /api/quote`  
  - 买卖五档、内外盘、总手、现量、金额等。

- **多周期 K 线**：`GET /api/kline`, `GET /api/kline-all`, `GET /api/kline-all/tdx`, `GET /api/kline-all/ths`
  - 1 分钟 / 5 / 15 / 30 / 60 分钟 K 线。
  - 日 / 周 / 月 / 季 / 年 K 线（支持前复权与原始）。
  - **全量历史 K 线**（上市以来，支持按周期限制）。

> 这为 **日级 + 分钟级（1/5/15/30/60）** 建模提供了稳定的历史序列。

#### 2.2.2 分时 & 逐笔成交（高频结构化数据）

- **分时走势**：`GET /api/minute`
  - 当日或指定日分钟级价格与成交量（典型 240 点 / 日）。

- **逐笔成交**：`GET /api/trade`, `GET /api/trade-history`, `GET /api/minute-trade-all`, `GET /api/trade-history/full`
  - 当日 / 历史交易日的逐笔成交，包含：
    - 成交时间、价格、成交量、买卖方向（Status=买/卖/中性）。
  - 可一次性获取某日全部分时成交（`minute-trade-all`）。
  - 可拉取上市以来的所有成交明细（`trade-history/full`）。

> 虽然是“逐笔”，但以 API 格式返回，可按 1/5/15 分钟聚合为可用特征：  
> - order-flow imbalance、短周期 realized volatility、内外盘比、成交密度等。

#### 2.2.3 市场全局信息 & 批量接口

- 股票代码 / ETF 列表：`/api/codes`, `/api/stock-codes`, `/api/etf`, `/api/etf-codes`。
- 指数 K 线：`/api/index`, `/api/index/all`。
- 交易日信息：`/api/workday`, `/api/workday/range`。
- 批量行情：`/api/batch-quote`（一次 50 只）。
- **批量入库任务**：`/api/tasks/pull-kline` / `pull-trade`  
  - 可将全市场 K 线 / 逐笔成交落地到本地 SQLite 或其他 DB，适合回测 & 训练集构建。

---

### 2.3 结合现有系统 + TDX，可用于建模的关键特征

你可以稳定获得、并落地到本地 DB 的核心特征类别：

- **日级特征**：日 K、日级技术指标、资金流、筹码、情绪、风险事件、基本面因子。
- **分钟级特征（1/5/15/30/60）**：
  - 价格、成交量、金额、短周期技术指标。
- **逐笔/盘口衍生特征**（通过聚合 `/api/trade` / `/minute-trade-all`）：
  - 内外盘比、买卖主动性（Status）、大单占比、成交密度、短周期波动率。
- **指数 & ETF**：可加入市场 Beta / 板块共振等因子。

> 对于 **中低频 + 日内 T+0**，使用“**日级 + 分钟级 K 线 + 聚合后的成交特征**”就足够支撑 ARIMA/HMM/LSTM/DeepAR 等模型，无需真正 Tick 级做市级别处理。

---

## 3. 各模型的可行性与作用（结合 TDX 数据）

### 3.1 ARIMA

- **数据需求**：单变量固定频率序列（价格 / 收益），可为：
  - 日收益；
  - 5/15/30 分钟收益。

- **TDX 支持**：
  - 完整历史日 K（`kline-all` / `kline-all/tdx` / `ths`）。
  - 完整分钟 K 线（`kline` + `kline-all` + `kline-history`）。
- **可行性**：完全可行，且实现极简单。

- **作用**：
  - 作为 **日级 & 日内价格走势的统计基线**：
    - 预测下一个 bar 的期望收益 + 方差。
    - 在做 T 时帮助判断当前价格相对“近期均衡水平”的偏离程度。

---

### 3.2 HMM（隐马尔可夫）

- **数据需求**：多维观测序列，如：
  - 日级：收益、波动率、量比、资金流。
  - 日内：分钟级收益、成交量、order-flow 特征、短周期波动。

- **TDX 支持**：
  - 日级 & 分钟级 K 线 → 收益 / 波动率。
  - 逐笔成交 → 内外盘比、大单占比等微观特征。
- **可行性**：高，特别适合基于 TDX 数据识别：
  - 日级行情 regime（牛 / 熊 / 震荡）。
  - 日内微观结构状态（流动性良好 / 恶化、买盘主导 / 卖盘主导）。

- **作用**：
  - 作为 **仓位 & 做 T 频率的状态过滤器**：
    - 牛市 / 良好微观状态 → 可提高做 T 的积极程度。
    - 熊市 / 恶劣微观状态 → 缩小 T+0 规模或暂停。

---

### 3.3 LSTM

- **数据需求**：
  - 多维时间序列：如 5/15 分钟级别的 OHLCV + 成交/盘口衍生特征。
- **TDX 支持**：
  - 分钟 K 线 + 逐笔成交，可轻松构建日内 5–30 分钟特征序列。
  - 可聚合为样本：`[T, feature_dim]` 序列，用于预测下一段收益/方向。

- **可行性**：
  - 在“**少量重点持仓股 + 日内 5–30 分钟做 T**” 的场景下非常可行；
  - 深挖 trade 数据能显著提升短周期预测能力。

- **作用**：
  - 提供 **更精细的做 T 时点信号**：
    - 判断接下来一到数个 bar 是继续趋势还是短期回调；
    - 判断当前价位是否适合作为加/减仓点。

---

### 3.4 Transformer（时间序列 Transformer / TST）

- **数据需求**：与 LSTM 类似，但更擅长长序列、多资产联合。
- **TDX 支持**：
  - 大量日级 + 分钟级历史，可用于长窗口建模。
- **可行性**：
  - 技术上可行，但在**中低频 + 日内 T+0** 场景中：
    - 能力上限 > LSTM；
    - 但算力与工程复杂度明显更高。

- **作用**：
  - 更适合未来若要扩展到 **更长窗口（多周/月）+ 多资产联合预测** 的场景；
  - 当前阶段可作为 LSTM 的后续升级研究方向。

---

### 3.5 DeepAR

- **数据需求**：多时间序列联合（多股票），固定频率（通常日级或小时级）：
  - 输入：全市场日级/小时级 K 线、量价特征、行业/指数因子及其它协变量。

- **TDX 支持**：
  - 全 A 股代码 + 全量日 K / 分钟 K；
  - 可构建 **跨股票联合训练数据集**。

- **可行性**：
  - 非常适合作为 **多股票预期收益 + 风险概率分布引擎**：
    - 日级：预测未来数日收益分布 → 调整持仓权重、挑选适合做 T 的标的。
    - 小时级：在日内几个关键时段输出更新后的概率。

- **作用**：
  - 在“中低频 + 日内做 T”中扮演 **“标的筛选 + 权重建议”** 的角色，
  - LSTM/HMM 则负责局部日内执行节奏与风控。

---

### 3.6 FinMamba（Mamba/SSM 金融时序）

- **数据需求**：理论上最适合**极长序列或更高频**的时序。
- **TDX 支持**：
  - 有足够时间长度，但缺少真正纳秒级 Tick/LOB，不会完全发挥其优势。
- **可行性**：
  - 在当前中低频 + 简化分钟/成交特征场景下，  
    更多是中长期研究方向，短期不适合作为主力模型。

---

## 4. 算力评估与 RTX 2060 6GB 能力判断

### 4.1 现有显卡环境

- **显卡型号**：NVIDIA GeForce RTX 2060  
- **显存**：6 GB  
- **定位**：中端游戏 / 开发卡，适合：
  - 中小规模深度学习模型训练（适当控制 batch / 序列长度）。
  - 实时推理需求不高的应用。

---

### 4.2 按模型划分的算力需求 & 适配性

#### 4.2.1 ARIMA

- **训练 & 推理**：全部在 CPU 即可完成，且非常快。
- **适配性**：与 GPU 无关，当前硬件绰绰有余。

> **算力建议**：直接用 CPU（多进程/多线程）即可支撑全市场日/分钟级 ARIMA 基线。

---

#### 4.2.2 HMM

- **训练**：
  - 对单/少数状态模型（2–5 个状态）、几十维观测量：
    - CPU 完全足够，序列长度在 1e4–1e5 级别训练时间在秒–分钟级。
- **推理**：
  - 前向/后向/Viterbi 都是线性时间，毫秒级。

- **适配性**：
  - RTX 2060 用于 HMM 没有刚性需求，**CPU 足够**。
  - 可以考虑用 GPU 仅在特征预处理（大规模矩阵运算）上减轻一点 CPU 负担，但不是必需。

> **算力建议**：  
> - 用 CPU 部署 HMM + 状态识别完全可行。  
> - 现有配置可以轻松做到“分钟级状态更新 + 秒级响应”。

---

#### 4.2.3 LSTM（针对少量持仓股的日内做 T）

- **典型配置（建议）**：
  - 输入：5–30 分钟 bar 序列，长度 T ≈ 50–200（约 1–2 天）；  
  - 特征维度：20–80（价量 + 成交特征 + 指数/板块因子）；  
  - 模型规模：1–3 层 LSTM，每层隐藏单元 64–256。

- **算力需求**：
  - **训练**：
    - 在上述规模下，使用 RTX 2060 6GB 训练 1–5 年历史（几十万样本）是可行的：
      - 需要控制 batch size（如 64~128）与序列长度以适应 6GB 显存。
      - 训练时间大致在几十分钟到数小时之间（视样本量而定）。
  - **推理**：
    - 仅对“当前持仓股票”（几十只以内）在每个 5–15 分钟 bar 前向一次：
      - 纯 CPU 就能做到毫秒级，  
      - 使用 2060 则更宽裕。

- **适配性结论**：
  - RTX 2060 6GB **足以支撑**：
    - 中小规模 LSTM 在有限股票集合上的训练与在线推理；
    - 适用于你当前“持仓股票日内 T+0”的场景。
  - 若要在“全 A 股 + 多年分钟级数据 + 大模型”上训练，显存和训练时间会较吃紧，但依然可以通过：
    - 降低模型规模；
    - 限制训练股票集合（只选流动性好 + 持仓相关）；
    - 分批训练等方式解决。

---

#### 4.2.4 Transformer（TST）

- **典型配置（合理但不大的模型）**：
  - 4–6 层 encoder，每层 4–8 个 attention head，hidden dim 128–256。
- **算力需求**：
  - 这种规模下，若序列长度 T≈200，特征维度≈64，  
    **单卡 6GB 显存可以跑**，但：
    - 需要较小 batch；
    - 训练大规模多股票数据时，总训练时间会显著长于 LSTM。

- **适配性结论**：
  - **实验/PoC 级别**：RTX 2060 6GB 能跑小模型做研究；
  - **生产级多资产长序列模型**：
    - 更推荐 RTX 3060(12GB)、RTX 4070/4080 或服务器卡（A5000/6000）。
  - 在你当前中低频 + 做T 目标下，使用 TST 的性价比不如 LSTM/DeepAR。

---

#### 4.2.5 DeepAR

- **使用方式建议**：
  - 日级或 60 分钟级别，多股票联合训练；
  - 模型规模与 LSTM 类似（DeepAR 内核本质是 RNN）。

- **算力需求**：
  - 对全市场日级数据（数千股票 * 数千交易日）：
    - 使用 RTX 2060 6GB 训练是可行的，但需要注意：
      - 序列打包方式（分股票 / 分时间切 patch）；
      - 控制 batch size 以适配显存。
    - 训练时间预计在数小时量级（可夜间离线训练）。

- **推理**：
  - 日级/小时级推理对算力要求极低；
  - 2060 6GB 或 CPU 都能在秒级给出全市场的预测。

- **适配性结论**：
  - 当前 2060 6GB **可以支撑** DeepAR 作为日级/小时级概率预测引擎；
  - 若未来模型和数据规模进一步增大，再考虑升级显卡。

---

#### 4.2.6 FinMamba（Mamba/SSM）

- **算力需求**（参考类似规模的 SSM/长序列模型）：
  - 为充分发挥长序列优势，通常需要：
    - 更长序列 T（数百–上千时间步）；
    - 更大 hidden dim 与更多层数。
  - 对这种配置，6GB 显存会成为主要瓶颈：
    - 需要非常小的 batch；
    - 训练速度慢，难以频繁重训练。

- **适配性结论**：
  - 不太适合作为在 RTX 2060 6GB 上的主力生产模型；
  - 更适合在有 12GB+ 显存或服务器 GPU（3090/4090/A100 等）时开展研究。

---

### 4.3 综合算力建议（结合你当前 RTX 2060）

- **可以放心在当前环境上线的层级**：
  - **CPU-only**：ARIMA、HMM（含分钟级/日级）。
  - **2060 6GB + CPU**：
    - 中小规模的 LSTM（用于少数重点持仓股的日内做 T 信号）；
    - DeepAR（日级/小时级跨股票概率预测，离线训练 + 在线推理）。

- **适合在现在开始研究但暂不建议作为核心生产模块的**：
  - 小规模 Transformer/TST（用 2060 做 PoC，评估是否显著优于 LSTM/DeepAR）。

- **需要更高阶算力后再系统性推进的**：
  - 大规模 Transformer / FinMamba 长序列模型（全市场 + 多年分钟级）。

---

## 5. 综合结论与推荐路线

### 5.1 结合数据源、算力与目标的优先模型组合

1. **第一层（短期可落地，CPU 主导）**
   - **ARIMA（日级 + 分钟级）**：  
     - 形成个股价格 / 收益的统计基线；
     - 作为做 T 决策的“均值参考线”与简单短周期预测。

   - **HMM（基于日级 + 分钟级价量/成交特征）**：  
     - 识别行情 regime 与日内微观结构状态；
     - 决定整体仓位 & T+0 强度（激进 / 保守 / 暂停）。

2. **第二层（利用 RTX 2060 6GB 的中等复杂度模型）**
   - **DeepAR（日级/小时级，多股票联合）**：  
     - 作为全持仓/候选池股票的**预期收益 + 风险概率引擎**；
     - 帮助筛选“值得做 T 的股票”与“加仓/减仓优先级”。

   - **LSTM（针对持仓股的 5–30 分钟序列）**：  
     - 提供日内做 T 的时点与方向增强信号；
     - 在 HMM 过滤下提高做 T 成功率、降低成本。

3. **第三层（未来研究方向）**
   - **Transformer / FinMamba**：
     - 在有更强 GPU 资源时，用于探索更高上限的长序列、多资产模型；
     - 若在多轮回测 & 仿真中明显优于 LSTM/DeepAR，再小规模引入实盘。

---

### 5.2 与趋势分析系统的衔接方式（概念）
375 
376 - 在现有趋势分析与多分析师架构下，可以逐步引入上述模型作为：
377 -  - **技术资金分析师的数值底层**（提供多周期 up/flat/down 概率 & base_expectation_pct）；
378 -  - **量化策略引擎的信号来源**（通过统一的“信号对象”，如：方向、置信度、建议仓位调整等）。
379 -
380 - 所有模型输出都建议统一通过：
381 -  - **数值层（概率/期望收益/波动）**；
382 -  - **状态层（HMM 状态、风险标签）**；
383 -  - **解释层（LLM 生成报告）**  
384 -  三个层次暴露给上层 UI 与策略逻辑。
385 -
386 +## 6. 阶段三：LSTM 模型架构正式方案（Universe + Shared + Per-stock）
387 +
388 +本节固化阶段三针对 LSTM 的最终架构设计，后续实现与评估均以此为准。
389 +
390 +### 6.1 Universe 定义与配置表
391 +
392 +- **Universe 基本定义**：
393 +  - 以 **全量 A 股股票** 为基准集合；
394 +  - 剔除“垃圾股”：ST、退市、长期停牌、极低流动性、新股（上市未满一定交易日）等；
395 +  - 得到 **全市场合格 Universe**，作为默认训练与评估 Universe。
396 +
397 +- **Universe 配置表/视图（示意）**：
398 +  - 位于 `app` schema 下的新表（例如 `app.model_universe_config`，由新程序初始化脚本创建）；
399 +  - 关键字段：
400 +    - `universe_name`：如 `ALL_EQ_CLEAN`、`CORE_UNIVERSE`, `CSI_300` 等；
401 +    - `description`：文字说明；
402 +    - `config_json`：存放垃圾股过滤规则、流动性/市值阈值、是否只用某些分类等；
403 +    - `enabled`：是否启用；
404 +    - `created_at` / `updated_at`：元数据。
405 +
406 +- **使用方式**：
407 +  - LSTM shared 训练脚本从该表读取本次训练要使用的 `universe_name` 及其 `config_json`；
408 +  - 默认使用“全市场合格 Universe”（与设计文档一致）；
409 +  - 可通过修改配置表，方便切换到：
410 +    - 只用 `CoreUniverse`；
411 +    - 只用某些分类（如“核心持仓”“重点跟踪”“指数成分”等）；
412 +  - 训练脚本会将本次使用的 Universe 定义写入 `app.model_train_run.config_snapshot`，便于回溯与 A/B 对照试验。
413 +
414 +### 6.2 静态特征表（行业、市值、波动水平等）
415 +
416 +- **目的**：
417 +  - 为 LSTM shared 模型及其上层 refinement 层提供 **截面信息**：行业、规模、波动、流动性等；
418 +  - 用于在相同日内形态下，区分不同类型股票的风险与期望收益差异。
419 +
420 +- **静态特征表示例**（由新程序创建与维护，位于 `app` schema）：
421 +  - 表名示意：`app.stock_static_features`；
422 +  - 示例字段：
423 +    - `ts_code`：股票代码；
424 +    - `as_of_date`：特征观测日期（避免前瞻性问题，可为日级或月级）；
425 +    - `industry` / `sub_industry`：行业与细分行业标签；
426 +    - `size_bucket`：市值分桶（如 `S/M/L/XL` 或分位数）；
427 +    - `volatility_bucket`：长期波动分桶；
428 +    - `liquidity_bucket`：长期流动性分桶；
429 +    - `extra_json`：可扩展的其它静态/慢变量；
430 +    - 复合主键或唯一约束：`(ts_code, as_of_date)`。
431 +
432 +- **使用场景**：
433 +  - 在 **Universe 级 shared LSTM** 中作为静态协变量（static covariates）；
434 +  - 在 **per-stock refinement 层** 中与 `y_shared` 结合，用于调整该股的最终信号；
435 +  - 在组合/风险控制层，用于约束行业、市值、波动暴露。
436 +
437 +### 6.3 Universe 级 shared LSTM（含 symbol embedding + 静态特征）
438 +
439 +- **目标**：
440 +  - 在“全市场合格 Universe”上训练一个 **通用股票预测模型**，
441 +  - 输入为日内 5 分钟级别的价量 + 高频特征序列，输出下一段收益/方向的预测 `y_shared`.
442 +
443 +- **输入设计**：
444 +  - **动态时序特征**：
445 +    - 来自 TimescaleDB 的 5 分钟 K 线（`market.kline_5m`）和高频聚合特征表（`app.ts_lstm_trade_agg`）；
446 +    - 通过既有 `next_app/backend/quant_datasets/lstm_dataset.py` 模块构建；
447 +  - **symbol embedding**：
448 +    - 为 Universe 内每只股票分配一个 `symbol_id`，使用 `nn.Embedding` 得到 `symbol_embedding(ts_code)`；
449 +    - 表达个股长期行为与微观结构的差异；
450 +  - **静态特征**：
451 +    - 从 `app.stock_static_features` 读取行业/市值/波动/流动性等标签，作为静态协变量；
452 +    - 在每个时间步拼接到 LSTM 输入或在 LSTM 输出后作为条件信息使用。
453 +
454 +- **输出与记录**：
455 +  - 对 Universe 内每只股票与每个时间点，输出 `y_shared(t, symbol)`（如下一根 5m log return 的期望值）；
456 +  - 将训练配置（Universe 定义、embedding 维度、静态特征字段等）与评估指标
457 +    写入 `app.model_train_run`（`model_name = 'LSTM_SHARED'`）；
458 +  - 推理结果可直接写入 `app.quant_unified_signal`，或作为 per-stock refinement 的输入。
459 +
460 +### 6.4 per-stock refinement 层（基于 y_shared + 特有因子）
461 +
462 +- **动机**：
463 +  - shared LSTM 已在全市场大样本上学到“通用模式 + 部分个股差异”，
464 +  - 但对自选池中的核心标的，仍需要结合 **该股特有因子** 进行更精细的纠偏与放缩。
465 +
466 +- **输入与输出**：
467 +  - 输入：
468 +    - `y_shared(t, symbol)` 及其在过去一段时间上的统计量（均值、波动、分位数等）；
469 +    - 该股静态/特有因子：更细粒度行业标签、风格、基本面标签、风险标签等；
470 +  - 输出：
471 +    - `y_final(t, symbol)`：该股最终用于交易/打分的信号（可视为对 `y_shared` 的校准或残差修正）。
472 +
473 +- **模型形式**：
474 +  - 可采用轻量模型实现，如：
475 +    - 线性/逻辑回归（易解释）；
476 +    - 小型 MLP 或树模型；
477 +  - 训练成本远低于重训 LSTM，便于针对自选池增量更新。
478 +
479 +- **集成方式**：
480 +  - 推理时，per-stock refinement 层与 shared 模型统一写入 `app.quant_unified_signal`：
481 +    - `model_votes` 中记录 `LSTM_SHARED` 与 `LSTM_REFINEMENT` 的投票及权重；
482 +    - `model_versions` 中记录所用模型路径与配置快照；
483 +  - 在组合与 UI 层，可以查看：
484 +    - `y_shared` 基线表现；
485 +    - refinement 后 `y_final` 的改善情况。
486 +
487 +### 6.5 可选 full per-stock LSTM 模式
488 +
489 +- **适用范围**：
490 +  - 历史极长、成交活跃、持仓权重较高的少数核心标的；
491 +  - 这些股票的数据量足以支撑中等容量的独立 LSTM 模型。
492 +
493 +- **训练方式**：
494 +  - 在现有 `next_app/backend/quant_models/lstm/train_per_stock.py` 基础上，
495 +    对单只股票构建独立的 LSTM 模型与标准化参数；
496 +  - 在 `app.model_train_run.config_snapshot` 中增加 `per_stock_mode` 字段：
497 +    - `"REFINEMENT"`：该股使用 shared + refinement；
498 +    - `"FULL_LSTM"`：该股使用独立 per-stock LSTM；
499 +  - 未来 UI 可在“单股模型设置”中提供两种模式的选择。
500 +
501 +- **与 refinement 的关系**：
502 +  - `FULL_LSTM` 模式只对极少数头部标的启用，
503 +    在其上不再额外叠加 refinement（避免过度复杂化与重叠建模）；
504 +  - 对绝大多数股票，推荐采用 `shared + refinement`，在 OOS 稳定性与维护成本之间取得更优平衡。
505 +
506 +### 6.6 阶段三实现边界与后续扩展
507 +
508 +- **阶段三实现范围**：
509 +  - 新增 Universe 配置表与静态特征表的 schema 与基础填充逻辑（由新程序脚本管理）；
510 +  - 在 `next_app/backend` 中实现：
511 +    - 带 symbol embedding + 静态特征输入的 shared LSTM 训练与推理脚本；
512 +    - 基于 `y_shared + 特有因子` 的 per-stock refinement 训练与推理模块；
513 +    - 可选 full per-stock LSTM 训练模式的元数据标记与模型管理；
514 +  - 所有模型相关元信息统一写入 `app.model_config` / `app.model_train_run` / `app.model_inference_run` / `app.quant_unified_signal`.
515 +
516 +- **后续扩展方向**：
517 +  - 将同一套 Universe/静态特征/元数据框架，拓展到 DeepAR、Transformer 等模型；
518 +  - 在组合与 UI 层提供：
519 +    - Universe 切换与模型组合的对照实验界面；
520 +    - shared / refinement / full per-stock 模式的可视化对比与解释分析.
